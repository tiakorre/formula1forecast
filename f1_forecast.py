# -*- coding: utf-8 -*-
"""f1_forecast.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RDLqjXzeVIroHrdItdE4TiaffVBhutO5
"""

# Install GeoPandas, Folium, and other libraries
# !pip install geopandas folium shapely plotly matplotlib pandas fastf1 ergast-py

# Data handling
import pandas as pd
import geopandas as gpd

# GIS & Mapping
import folium
from shapely.geometry import Point

# Visualization
import matplotlib.pyplot as plt
import plotly.express as px
# import fastf1
import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
import math
import matplotlib.pyplot as plt
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import requests
from bs4 import BeautifulSoup
import pandas as pd
import requests

"""Formation of Pandas dataframe

Getting the data


*   Circuit Name
*   year
*   crash appearance
*  weather on day of race
"""



import requests

def lap_time_to_seconds(lap_time_str):
    """
    Convert a lap time string (e.g., "1:42.678") into total seconds as a float.
    """
    parts = lap_time_str.split(':')
    if len(parts) == 2:
        minutes = int(parts[0])
        seconds = float(parts[1])
        return minutes * 60 + seconds
    else:
        return float(lap_time_str)

def get_circuit_data(year, round):
    """
    Retrieves race, circuit, and lap timing data from Ergast.

    For lap timing:
      - Lap time data is available from the 1996 season onward.
      - The laps endpoint requires the season, round, and (optionally) lap number:
            e.g., http://ergast.com/api/f1/2011/5/laps/1
      - You can also filter by driver:
            e.g., http://ergast.com/api/f1/2011/5/drivers/alonso/laps/1

    This function:
      1. Gets basic race/circuit info.
      2. Retrieves race results to build a driver-to-team mapping.
      3. Pulls lap times for the race and aggregates them by team.
      4. Computes the average lap time per team.
    """
    # Retrieve basic race and circuit data.
    url = f"http://ergast.com/api/f1/{year}/{round}.json"
    response = requests.get(url)

    if response.status_code == 200:
        data = response.json()
        races = data['MRData']['RaceTable']['Races']
        circuit_list = []

        for race in races:
            circuit = race['Circuit']
            circuit_name = circuit['circuitName']
            race_name = race['raceName']
            location = circuit['Location']
            latitude = location['lat']
            longitude = location['long']
            date = race['date']
            time = race.get('time', None)

            # Retrieve race results to map each driver to their team (constructor)
            results_url = f"http://ergast.com/api/f1/{year}/{round}/results.json"
            results_response = requests.get(results_url)
            driver_to_team = {}
            if results_response.status_code == 200:
                results_data = results_response.json()
                races_results = results_data['MRData']['RaceTable']['Races']
                if races_results:
                    race_results = races_results[0]['Results']
                    for res in race_results:
                        driver_id = res['Driver']['driverId']
                        team = res['Constructor']['name']
                        driver_to_team[driver_id] = team
            else:
                print(f"Error retrieving results data: {results_response.status_code}")

            # Retrieve lap timing data.
            # Using the general laps endpoint to get all lap timings for the race.
            laps_url = f"http://ergast.com/api/f1/{year}/{round}/laps.json?limit=2000"
            laps_response = requests.get(laps_url)

            team_lap_times = {}   # Total lap time in seconds for each team.
            team_lap_counts = {}  # Number of laps recorded per team.

            if laps_response.status_code == 200:
                laps_data = laps_response.json()
                if laps_data['MRData']['RaceTable']['Races']:
                    race_laps = laps_data['MRData']['RaceTable']['Races'][0]['Laps']
                    for lap in race_laps:
                        timings = lap.get('Timings', [])
                        for timing in timings:
                            driver_id = timing['driverId']
                            lap_time_str = timing['time']
                            lap_seconds = lap_time_to_seconds(lap_time_str)

                            # Map the driver to their team (default to "Unknown" if not found)
                            team = driver_to_team.get(driver_id, "Unknown")
                            team_lap_times[team] = team_lap_times.get(team, 0) + lap_seconds
                            team_lap_counts[team] = team_lap_counts.get(team, 0) + 1
                else:
                    print("Lap time data not available for this race.")
            else:
                print(f"Error retrieving lap times: {laps_response.status_code}")

            # Compute the rough average lap time (in seconds) per team .
            avg_team_lap_times = {}
            for team, total_time in team_lap_times.items():
                count = team_lap_counts[team]
                avg_team_lap_times[team] = total_time / count if count else None

            # Append the combined data to the list.
            circuit_list.append({
                "circuitName": circuit_name,
                "latitude": latitude,
                "longitude": longitude,
                "year": year,
                "round": round,
                "raceName": race_name,
                "date": date,
                "time": time,
                "team_lap_times": avg_team_lap_times
            })

        return circuit_list
    else:
        print(f"Error: {response.status_code}")
        return []

# Crash TYPES
driver_error = ["Accident", "Collision", "Spun off"]
car_failure = [
    "Engine", "Gearbox", "Transmission", "Clutch", "Hydraulics", "Electrical",
    "Suspension", "Brakes", "Differential", "Overheating", "Radiator", "Tyre",
    "Puncture", "Driveshaft"
]

def get_crash_data(year, round):
    url = f"http://ergast.com/api/f1/{year}/{round}/status.json"
     # Send a GET request
    response = requests.get(url)
    if response.status_code == 200:
      data = response.json()
      statuses = data['MRData']['StatusTable']['Status']
      crash_counts = {
            "Driver Error": 0,
            "Car Failure": 0
      }
      for status in statuses:
        if status['status'] in driver_error:
          crash_counts["Driver Error"] += int(status['count'])
        elif status['status'] in car_failure:
          crash_counts["Car Failure"] += int(status['count'])

      return crash_counts
    else:
      print(f"Error: {response.status_code}")
      return {}

get_crash_data(2024,6)

"""Now that we have the crashes set up. Now we must develop the round to circuit connection from the api

Get time and date data for the weather
"""

get_circuit_data(2024,6)

"""Pandas formation"""

def circuit_crashes_data (start_year, end_year):

  combined_data = []

  # Loop through years and rounds
  for year in range(start_year, end_year):
    for round_num in range(1, 25):  # Assuming a maximum of 22 rounds per season
        # Get circuit data
        circuit_data = get_circuit_data(year, round_num)
        crash_data = get_crash_data(year, round_num)
        # Get crash data
        if circuit_data:
          combined_entry = circuit_data[0]
          combined_entry.update(crash_data)
          # print(combined_entry)
          combined_data.append(combined_entry)

  return combined_data


# Convert the combined data to a pandas DataFrame

"""The rounds per season are irregualr to for the primary datagrame the columns are the year and round number"""

records = circuit_crashes_data(2018, 2025)

"""Personal choice to incude 6 instead of 5 becuse there were a lot of rookies this year but stil want a 5 year of the driver i have been most familar with ie danical ricado"""

def circuit_crashes_data(start_year, end_year):
    """
    Aggregates race/circuit and lap time data over a range of years (inclusive).

    For each year between start_year and end_year:
      1. Retrieve the season schedule.
      2. For each race in that year, call get_circuit_data.
      3. Append the results to a master list.

    Returns:
      A list of records containing circuit details and aggregated team lap times.
    """
    records = []
    for year in range(start_year, end_year + 1):
        schedule_url = f"http://ergast.com/api/f1/{year}.json"
        schedule_response = requests.get(schedule_url)
        if schedule_response.status_code != 200:
            print(f"Error retrieving schedule for year {year}: {schedule_response.status_code}")
            continue

        schedule_data = schedule_response.json()
        races = schedule_data['MRData']['RaceTable']['Races']
        if not races:
            print(f"No races found for year {year}")
            continue

        for race in races:
            round_num = race['round']
            race_records = get_circuit_data(year, round_num)
            if race_records:
                records.extend(race_records)
    return records

# --- Data Aggregation for Years 2018 to 2025 --- #

records = circuit_crashes_data(2018, 2022)
print("Aggregated data for years 2018 to 2025.")

rows = []
for record in records:
    for team, avg_lap_time in record['team_lap_times'].items():
        rows.append({
            "year": record["year"],
            "round": record["round"],
            "circuit": record["circuitName"],
            "raceName": record["raceName"],
            "date": record["date"],
            "team": team,
            "avg_lap_time": avg_lap_time,
            "latitude": float(record["latitude"]),
            "longitude": float(record["longitude"])
        })

df = pd.DataFrame(rows)
print("Processed Data:")
print(df.head())

# Convert the date column to create a numerical feature.
df['date'] = pd.to_datetime(df['date'])
df['date_ordinal'] = df['date'].apply(lambda x: x.toordinal())



# --- Data Modeling --- #

# For a basic prediction, we will use latitude and date_ordinal as example features.
X = df[['latitude', 'date_ordinal']]
y = df['avg_lap_time']

# Split the data into training and testing sets.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Create and train a linear regression model.
lr = LinearRegression()
lr.fit(X_train, y_train)

# Predict on the test set.
y_pred = lr.predict(X_test)
# Evaluate the model.
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("\nLinear Regression Model Evaluation:")
print("Mean Squared Error:", mse)
print("R^2 Score:", r2)

# Plot predictions vs. actual values.
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, color='green')
plt.xlabel("Actual Average Lap Time (seconds)")
plt.ylabel("Predicted Average Lap Time (seconds)")
plt.title("Actual vs. Predicted Average Lap Times (2018-2025)")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Diagonal line
plt.tight_layout()
plt.show()


all_data = []
for r in range(1, 7):
    race_data = get_circuit_data(2024, r)
    if race_data:
        all_data.extend(race_data)

# Transform the nested structure into a flat DataFrame:
rows = []
for race in all_data:
    for team, lap_time in race['team_lap_times'].items():
        rows.append({
            "year": race["year"],
            "round": race["round"],
            "circuit": race["circuitName"],
            "raceName": race["raceName"],
            "date": race["date"],
            "team": team,
            "avg_lap_time": lap_time,
            "latitude": float(race["latitude"]),
            "longitude": float(race["longitude"])
        })

df = pd.DataFrame(rows)
print("Processed Data:")
print(df.head())

# Convert date column to datetime and create a numerical feature.
df['date'] = pd.to_datetime(df['date'])
df['date_ordinal'] = df['date'].apply(lambda x: x.toordinal())

# --- Preliminary Visualizations --- #

# 1. Box Plot: Distribution of average lap times per team.
plt.figure(figsize=(10, 6))
teams = df['team'].unique()
data_to_plot = [df[df['team'] == t]['avg_lap_time'] for t in teams]
plt.boxplot(data_to_plot, labels=teams, showfliers=True)
plt.xticks(rotation=45)
plt.xlabel("Team")
plt.ylabel("Average Lap Time (seconds)")
plt.title("Distribution of Average Lap Times per Team (2018-2025)")
plt.tight_layout()
plt.show()


# 2. Scatter Plot: Average lap time vs. race date (ordinal).
plt.figure(figsize=(10,6))
plt.scatter(df['date_ordinal'], df['avg_lap_time'], color='blue')
plt.xlabel("Race Date (Ordinal)")
plt.ylabel("Average Lap Time (seconds)")
plt.title("Average Lap Time vs. Race Date")
plt.tight_layout()
plt.show()


# 1. Summary Statistics

print("Summary Statistics:")
print(df.describe())

# 2. Distribution of Average Lap Times

plt.figure(figsize=(10,6))
sns.histplot(df['avg_lap_time'], kde=True, bins=30, color='skyblue')
plt.xlabel("Average Lap Time (seconds)")
plt.title("Distribution of Average Lap Times Across Teams and Races")
plt.show()


# 3. Boxplot by Team

plt.figure(figsize=(12,8))
sns.boxplot(x='team', y='avg_lap_time', data=df)
plt.xticks(rotation=45)
plt.xlabel("Team")
plt.ylabel("Average Lap Time (seconds)")
plt.title("Boxplot of Average Lap Times by Team")
plt.axhline(100, color='red', linestyle='--', label='100 seconds')
plt.legend()
plt.ylim(0, 110)  # Adjust the y-axis to focus on values below 100 seconds
plt.show()



# 5. Trends Over Time: Line Plot (Aggregated by Team & Date)

team_trends = df.groupby(['team', 'date']).agg({'avg_lap_time': 'mean'}).reset_index()
team_trends['date'] = pd.to_datetime(team_trends['date'])
team_trends = team_trends.sort_values('date')

plt.figure(figsize=(14,10))
sns.lineplot(data=team_trends, x='date', y='avg_lap_time', hue='team', marker='o')
plt.xticks(rotation=45)
plt.xlabel("Race Date")
plt.ylabel("Average Lap Time (seconds)")
plt.title("Trend of Average Lap Times Over Time by Team")
plt.legend(title='Team', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()


# 8. FacetGrid: Individual Trends by Team

g = sns.FacetGrid(team_trends, col="team", col_wrap=3, height=4, sharey=False)
g.map(sns.lineplot, "date", "avg_lap_time", marker="o")
g.set_titles("{col_name}")
g.set_axis_labels("Race Date", "Average Lap Time (seconds)")
plt.tight_layout()
plt.show()

#  PRELIM Data Modeling 

X = df[['latitude', 'date_ordinal']]
y = df['avg_lap_time']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
lr = LinearRegression()
lr.fit(X_train, y_train)

y_pred = lr.predict(X_test)

# Evaluate model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("\nLinear Regression Model Evaluation:")
print("Mean Squared Error:", mse)
print("R^2 Score:", r2)

# predictions vs. actual 
plt.figure(figsize=(10,6))
plt.scatter(y_test, y_pred, color='green')
plt.xlabel("Actual Average Lap Time (seconds)")
plt.ylabel("Predicted Average Lap Time (seconds)")
plt.title("Actual vs. Predicted Average Lap Times")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Diagonal line
plt.tight_layout()
plt.show()


team_trends = df.groupby(['team', 'date']).agg({'avg_lap_time': 'mean'}).reset_index()
team_trends = team_trends.sort_values('date')

plt.figure(figsize=(12, 8))
for team in team_trends['team'].unique():
    team_data = team_trends[team_trends['team'] == team]
    plt.plot(team_data['date'], team_data['avg_lap_time'], marker='o', label=team)
    team_data['moving_avg'] = team_data['avg_lap_time'].rolling(window=3).mean()
    plt.plot(team_data['date'], team_data['moving_avg'], linestyle='--')

plt.xlabel("Race Date")
plt.ylabel("Average Lap Time (seconds)")
plt.title("Trend of Average Lap Times per Team Over Time")
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()



teams = team_trends['team'].unique()
num_teams = len(teams)

num_cols = 3
num_rows = math.ceil(num_teams / num_cols)

fig, axes = plt.subplots(num_rows, num_cols, figsize=(16, 12), sharex=False, sharey=False)

axes = axes.flatten()

for i, team in enumerate(teams):
    ax = axes[i]
    subset = team_trends[team_trends['team'] == team].copy()

    # Plot raw average lap times
    ax.plot(subset['date'], subset['avg_lap_time'], marker='o', label='Avg Lap Time')

    # Optionally compute and plot a moving average (3-race rolling window as an example)
    subset['moving_avg'] = subset['avg_lap_time'].rolling(window=3).mean()
    ax.plot(subset['date'], subset['moving_avg'], linestyle='--', label='3-Race MA')

    ax.set_title(team)
    ax.set_xlabel("Race Date")
    ax.set_ylabel("Lap Time (seconds)")
    ax.legend()

for j in range(i+1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()



"""Now i want to create a column to distinguish the tracks pulling from wiki pedia
https://en.wikipedia.org/wiki/List_of_Formula_One_circuits
"""



url = "https://en.wikipedia.org/wiki/List_of_Formula_One_circuits"

# Step 1: Fetch the page and parse with beautiful Soup
response = requests.get(url)
html_content = response.text

soup = BeautifulSoup(html_content, "html.parser")

# Step 3: Locate the main table
#   The table has class="wikitable sortable"
table = soup.find("table", {"class": "wikitable sortable"})

# Step 4: Extract table rows
#   The first row is the header, so skip it with [1:]
rows = table.find_all("tr")[1:]

# Step 5: Loop through rows and scrape circuit name + circuit type
circuit_info = []
for row in rows:
    # Each cell is a <td>
    cells = row.find_all("td")

    if len(cells) >= 3:
        circuit_name = cells[0].get_text(strip=True)

        circuit_type = cells[2].get_text(strip=True)

        # Store in a dictionary
        circuit_info.append({
            "Circuit Name": circuit_name,
            "Circuit Type": circuit_type
        })

# Step 6: Create a DataFrame
circuitType_df = pd.DataFrame(circuit_info)

print(circuitType_df.head())

df.columns

for i in df['circuitName']:
  for j in circuitType_df['Circuit Name']:
    dfNames = df['circuitName'].unique()
    circuitTypedfNames = circuitType_df['Circuit Name'].unique()
    # if i == j:
    #   df['circuitType'] = circuitType_df['Circuit Type']
print(dfNames)

print( circuitTypedfNames)

"""The discrepecies in the names are leadnig me to tokennize them so i can pair up the types of tracks from the beautiful soup scraping"""

import re
def tokenize_name(name):
    """
    Splits the circuit name into a set of tokens (words) after:
     - converting to lowercase
     - removing special characters like '*' and punctuation if desired
     - ignoring filler words (like 'circuit', 'grand', 'prix', 'international', 'autodrome')
    Returns a set of tokens.
    """
    # Convert to lowercase
    name = name.lower()
    # Remove the '*' character
    name = name.replace('*', '')
    filler_words = {"circuit", "grand", "prix", "international", "autodrome", "the"}
    # Split on whitespace
    # tokens = name.split()
    tokens = re.split(r"[\s\-]+", name)
    # Filter out any filler words
    tokens = [t for t in tokens if t not in filler_words]
    return set(tokens)

"""Adding the tokenized names to the columns of the scraped circuit type df and the orginal df"""

#API Spelling error of Lusail Qutar
df["circuitName"] = df["circuitName"].replace(
    "Losail International Circuit",
    "Lusail International Circuit"
)

df["tokenName"] = df["circuitName"].apply(tokenize_name)

circuitType_df["tokenName"] = circuitType_df["Circuit Name"].apply(tokenize_name)

circuitType_df.head(2)



def find_best_circuit_type(df_tokens, circuitType_df):
    best_type = "Unknown"
    best_score = 0
    for _, row in circuitType_df.iterrows():
        ct_tokens = row["tokenName"]      # token set in circuitType_df
        score = len(df_tokens.intersection(ct_tokens))
        if score > best_score:
            best_score = score
            best_type = row["Circuit Type"]
    return best_type

df["circuitType"] = df["tokenName"].apply(
    lambda df_tokens: find_best_circuit_type(df_tokens, circuitType_df)
)

df.head()


"""Geeting rid of the Unknown"""

df["circuitType"] = df["tokenName"].apply(
    lambda df_tokens: find_best_circuit_type(df_tokens, circuitType_df)
)

unknown_df = df[df["circuitType"] == "Unknown"]

# Print the filtered rows
print(unknown_df)

#Nan values?
missing_by_column = df.isna().sum()
print(missing_by_column)

"""Turing Longitute and latitude to numerical"""

df["latitude"] = pd.to_numeric(df["latitude"], errors="coerce")
df["longitude"] = pd.to_numeric(df["longitude"], errors="coerce")

df.columns

"""Now we add weather data from an api to the df"""

# df['datetime'].dtypes
df['endtime'] = df['datetime'] + pd.Timedelta(hours=1)

df['start_time'] = df['datetime'].dt.tz_convert(None).dt.strftime('%Y-%m-%d:%H')
df['end_time'] = df['endtime'].dt.tz_convert(None).dt.strftime('%Y-%m-%d:%H')
print(df[['start_time', 'end_time']].head())



def get_weather(lat, lon, start_date, end_date, api_key, units="I", lang="en"):
    """
    Fetch historical weather data for precipitation and wind speed using the Weatherbit API.
    """
    url = "https://api.weatherbit.io/v2.0/history/hourly"

    params = {
        "lat": lat,
        "lon": lon,
        "start_date": start_date,
        "end_date": end_date,
        "units": units,
        "lang": lang,
        "key": api_key,
    }

    try:
        # Make the API request
        response = requests.get(url, params=params)
        response.raise_for_status()

        # Parse the JSON response
        weather_data = response.json()

        # Extract precipitation and windspeed
        if "data" in weather_data and len(weather_data["data"]) > 0:
            data = weather_data["data"][0]
            return {
                "precipitation": data.get("precip"),
                "windspeed": data.get("wind_spd"),
            }
        else:
            print(f"No weather data found for {lat}, {lon}, {start_date}")
            return {"precipitation": None, "windspeed": None}

    except requests.exceptions.RequestException as e:
        print(f"Error fetching weather data: {e}")
        return {"precipitation": None, "windspeed": None}


# Weather API Data
defaultapi = '324c700449524d18892acfa40ceb7331'

# Initialize lists to store weather data
precipitation_list = []
windspeed_list = []

# Iterate through each row in the DataFrame
for _, row in df.iterrows():
    weather = get_weather(
        lat=row["latitude"],
        lon=row["longitude"],
        start_date=row["start_time"],  # Use 'date' for start_date
        end_date=row["end_time"],    # Use 'date' for end_date
        api_key=defaultapi
    )
    precipitation_list.append(weather["precipitation"])
    windspeed_list.append(weather["windspeed"])

# Add the weather data as new columns to the DataFrame
df["precipitation"] = precipitation_list
df["windspeed"] = windspeed_list

# Display the updated DataFrame
print(df)

# Add the weather data as new columns in the DataFrame
df["precipitation"] = precipitation_list
df["windspeed"] = windspeed_list

# Display the updated DataFrame
print(df)



"""# more Visualizations"""

# 1) Distribution of Circuit Types
plt.figure(figsize=(7, 5))
sns.countplot(x="circuitType", data=df)
plt.title("Count of Circuits by Type")
plt.xlabel("Circuit Type")
plt.ylabel("Count")
plt.xticks(rotation=45)  # rotate labels if they overlap
plt.tight_layout()
plt.show()


# 5 Line Plot: Car Failure Over the Years

"""##Car error"""

# 5) Line Plot: Driver Error or Car Failure Over the Years
#    See if there's a trend in errors over time (assuming each row is a unique race).
df_yearly_error = df.groupby("year")["Car Failure"].sum().reset_index()

plt.figure(figsize=(7, 5))
sns.lineplot(x="year", y="Car Failure", data=df_yearly_error, marker="o")
plt.title("Car Errors by Year")
plt.xlabel("Year")
plt.ylabel("Total Car Errors")
plt.grid(True)
plt.show()

"""##Weather impact"""

df.columns



# Plot the distribution of precipitation
plt.figure(figsize=(8, 5))
plt.hist(df['precipitation'], bins=20, color='blue', alpha=0.7, edgecolor='black')
plt.title("Distribution of Precipitation", fontsize=16)
plt.xlabel("Precipitation (mm)", fontsize=14)
plt.ylabel("Frequency", fontsize=14)
plt.grid(alpha=0.3)
plt.show()

# Plot the distribution of windspeed
plt.figure(figsize=(8, 5))
plt.hist(df['windspeed'], bins=20, color='green', alpha=0.7, edgecolor='black')
plt.title("Distribution of Windspeed", fontsize=16)
plt.xlabel("Windspeed (m/s or mph)", fontsize=14)
plt.ylabel("Frequency", fontsize=14)
plt.grid(alpha=0.3)
plt.show()

"""##Correlation with weather and crashes"""

# Correlation matrix
correlation_matrix = df[['precipitation', 'windspeed', 'Car Failure']].corr()
print("Correlation Matrix:")
print(correlation_matrix)

plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Correlation Between Weather and Crashes", fontsize=16)
plt.show()

# Boxplot for precipitation and Driver Error
plt.figure(figsize=(8, 5))
sns.boxplot(x=df['Car Failure'], y=df['precipitation'], palette='Blues')
plt.title("Precipitation vs. DCar Failure", fontsize=16)
plt.xlabel("Car Failure Crashes", fontsize=14)
plt.ylabel("Precipitation (mm)", fontsize=14)
plt.grid(alpha=0.3)
plt.show()

# Scatter plot for windspeed and Car Failure
plt.figure(figsize=(8, 5))
plt.scatter(df['windspeed'], df['Car Failure'], alpha=0.7, color='red', edgecolor='black')
plt.title("Windspeed vs. Driver Error Crashes", fontsize=16)
plt.xlabel("Windspeed (m/s or mph)", fontsize=14)
plt.ylabel("Driver Error Crashes", fontsize=14)
plt.grid(alpha=0.3)
plt.show()

# Group by circuitType and calculate mean weather values
avg_weather_by_circuit = df.groupby('circuitType')[['precipitation', 'windspeed']].mean()
print("Average Weather Conditions by Circuit Type:")
print(avg_weather_by_circuit)

# Group by circuitType and sum crashes
weather_and_crashes = df.groupby('circuitType')[['precipitation', 'windspeed', 'Driver Error', 'Car Failure']].mean()
print("Weather Conditions and Crash Frequency by Circuit Type:")
print(weather_and_crashes)

"""##Over time and weather TIMESERIES"""

# Line plot for precipitation over time
df_sorted = df.sort_values(by='datetime')
plt.figure(figsize=(10, 6))
plt.plot(df_sorted['datetime'], df_sorted['precipitation'], label='Precipitation', color='blue', marker='o')
plt.title("Precipitation Over Time", fontsize=16)
plt.xlabel("Date", fontsize=14)
plt.ylabel("Precipitation (inches)", fontsize=14)
plt.grid(alpha=0.3)
plt.xticks(rotation=45)
plt.legend()
plt.show()

# Line plot for windspeed over time
plt.figure(figsize=(10, 6))
plt.plot(df_sorted['datetime'], df_sorted['windspeed'], label='Windspeed', color='green', marker='o')
plt.title("Windspeed Over Time", fontsize=16)
plt.xlabel("Date", fontsize=14)
plt.ylabel("Windspeed (m/s or mph)", fontsize=14)
plt.grid(alpha=0.3)
plt.xticks(rotation=45)
plt.legend()
plt.show()



def classify_race(precipitation):
    if precipitation <= 0.001:
        return "Dry"
    elif precipitation >= .03:
        return "Wet"
    else:
        return "Damp"

# Apply classification to the dataframe
df["race_condition"] = df["precipitation"].apply(classify_race)


# Add a column for total crashes (Driver Error + Car Failures)
df["Total Crashes"] = df["Driver Error"] + df["Car Failure"]


# 2. Classify Time of Day
def classify_time_of_day(datetime_col):
    """Classify the time of day based on hour."""
    hour = datetime_col.hour
    if 5 <= hour < 12:
        return "Morning"
    elif 12 <= hour < 18:
        return "Afternoon"
    else:
        return "Evening"

# Group by year and calculate total crashes
yearly_crash_trends = df.groupby("year")[["Driver Error", "Car Failure"]].sum().reset_index()
yearly_crash_trends["Total Crashes"] = yearly_crash_trends["Driver Error"] + yearly_crash_trends["Car Failure"]

# Visualization: Global trend
plt.figure(figsize=(12, 6))
sns.lineplot(
    data=yearly_crash_trends,
    x="year",
    y="Total Crashes",
    marker="o",
    label="Total Crashes"
)
sns.lineplot(
    data=yearly_crash_trends,
    x="year",
    y="Driver Error",
    marker="o",
    label="Driver Error"
)
sns.lineplot(
    data=yearly_crash_trends,
    x="year",
    y="Car Failure",
    marker="o",
    label="Car Failure"
)
plt.title("Crash Trends Over Time", fontsize=16)
plt.xlabel("Year", fontsize=14)
plt.ylabel("Number of Crashes", fontsize=14)
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

